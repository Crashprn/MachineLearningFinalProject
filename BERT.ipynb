{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from pytorch_transformers import BertTokenizer, BertModel\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  target\n",
      "0  Our Deeds are the Reason of this #earthquake M...       1\n",
      "1             Forest fire near La Ronge Sask. Canada       1\n",
      "2  All residents asked to 'shelter in place' are ...       1\n",
      "3  13,000 people receive #wildfires evacuation or...       1\n",
      "4  Just got sent this photo from Ruby #Alaska as ...       1\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('data/train.csv')\n",
    "\n",
    "dataset = data[['text', 'target']]\n",
    "\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading BERT and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertModel(\n",
      "  (embeddings): BertEmbeddings(\n",
      "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "    (position_embeddings): Embedding(512, 768)\n",
      "    (token_type_embeddings): Embedding(2, 768)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): BertEncoder(\n",
      "    (layer): ModuleList(\n",
      "      (0-11): 12 x BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pooler): BertPooler(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (activation): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "tokenizer: BertTokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing Each Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [101, 2256, 15616, 2024, 1996, 3114, 1997, 202...\n",
      "1    [101, 3224, 2543, 2379, 2474, 6902, 3351, 2187...\n",
      "2    [101, 2035, 3901, 2356, 2000, 1005, 7713, 1999...\n",
      "3    [101, 2410, 1010, 2199, 2111, 4374, 1001, 3748...\n",
      "4    [101, 2074, 2288, 2741, 2023, 6302, 2013, 1009...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "question = \"Is a disaster happening?\"\n",
    "tokenized_question = tokenizer.encode(question, add_special_tokens=True)\n",
    "tokenized = dataset['text'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
    "\n",
    "print(tokenized.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'our', 'deeds', 'are', 'the', 'reason', 'of', 'this', '#', 'earthquake', 'may', 'allah', 'forgive', 'us', 'all', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "test = tokenized[0]\n",
    "\n",
    "print(tokenizer.convert_ids_to_tokens(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running tokens through bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7613 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7613/7613 [01:22<00:00, 92.02it/s]\n"
     ]
    }
   ],
   "source": [
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "\n",
    "pooled = np.zeros((len(tokenized), 768))\n",
    "with torch.no_grad():\n",
    "    for i,seq in enumerate(tqdm(tokenized, total=len(tokenized))):\n",
    "        #info_embed = torch.ones(1, len(seq)).long().cuda()\n",
    "        #info_embed[0, :len(tokenized_question)+2] = 0\n",
    "        prepped_input = torch.tensor(seq).unsqueeze(0).cuda()\n",
    "        out = model(prepped_input)\n",
    "        pooled[i] = (out[1].cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing saving of data with labels and text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5         6  \\\n",
      "0 -0.822546 -0.472057 -0.579868  0.601334  0.001131 -0.033307  0.621883   \n",
      "1 -0.932106 -0.444832 -0.946184  0.783482  0.649199 -0.417868  0.810984   \n",
      "2 -0.786213 -0.454594 -0.989117  0.766382  0.825029 -0.260707  0.601579   \n",
      "3 -0.929848 -0.641187 -0.984187  0.838084  0.698074 -0.439465  0.848216   \n",
      "4 -0.782167 -0.475203 -0.785371  0.579609  0.718675 -0.169704  0.333027   \n",
      "\n",
      "          7         8         9  ...       760       761       762       763  \\\n",
      "0  0.219169 -0.297440 -0.999933  ...  0.746353  0.789280  0.454223  0.652186   \n",
      "1  0.553593 -0.841144 -0.999991  ...  0.972591  0.666550 -0.809021  0.077952   \n",
      "2  0.324533 -0.961853 -0.999995  ...  0.992954  0.505823 -0.130431 -0.429334   \n",
      "3  0.544355 -0.940431 -0.999996  ...  0.995336  0.807030 -0.736760 -0.092651   \n",
      "4  0.279532 -0.594330 -0.999871  ...  0.968012  0.792530  0.080506  0.567232   \n",
      "\n",
      "        764       765       766       767  target  \\\n",
      "0  0.384898 -0.173033 -0.653783  0.722890       1   \n",
      "1  0.690775 -0.809868 -0.695485  0.752990       1   \n",
      "2  0.774262 -0.879583 -0.601859  0.773692       1   \n",
      "3  0.772516 -0.862276 -0.756446  0.812085       1   \n",
      "4  0.400888 -0.405238 -0.665966  0.872382       1   \n",
      "\n",
      "                                                text  \n",
      "0  Our Deeds are the Reason of this #earthquake M...  \n",
      "1             Forest fire near La Ronge Sask. Canada  \n",
      "2  All residents asked to 'shelter in place' are ...  \n",
      "3  13,000 people receive #wildfires evacuation or...  \n",
      "4  Just got sent this photo from Ruby #Alaska as ...  \n",
      "\n",
      "[5 rows x 770 columns]\n"
     ]
    }
   ],
   "source": [
    "new_data = pd.DataFrame(pooled)\n",
    "\n",
    "new_data['target'] = dataset['target']\n",
    "new_data['text'] = dataset['text']\n",
    "\n",
    "print(new_data.head())\n",
    "\n",
    "new_data.to_csv('data/processed_bert.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
