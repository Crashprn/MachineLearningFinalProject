{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from NNs import NeuralNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5         6  \\\n",
      "0 -0.822546 -0.472057 -0.579868  0.601334  0.001131 -0.033307  0.621883   \n",
      "1 -0.932106 -0.444832 -0.946184  0.783482  0.649199 -0.417868  0.810984   \n",
      "2 -0.786213 -0.454594 -0.989117  0.766382  0.825029 -0.260707  0.601579   \n",
      "3 -0.929848 -0.641187 -0.984187  0.838084  0.698074 -0.439465  0.848216   \n",
      "4 -0.782167 -0.475203 -0.785371  0.579609  0.718675 -0.169704  0.333027   \n",
      "\n",
      "          7         8         9  ...       760       761       762       763  \\\n",
      "0  0.219169 -0.297440 -0.999933  ...  0.746353  0.789280  0.454223  0.652186   \n",
      "1  0.553593 -0.841144 -0.999991  ...  0.972591  0.666550 -0.809021  0.077952   \n",
      "2  0.324533 -0.961853 -0.999995  ...  0.992954  0.505823 -0.130431 -0.429334   \n",
      "3  0.544355 -0.940431 -0.999996  ...  0.995336  0.807030 -0.736760 -0.092651   \n",
      "4  0.279532 -0.594330 -0.999871  ...  0.968012  0.792530  0.080506  0.567232   \n",
      "\n",
      "        764       765       766       767  target  \\\n",
      "0  0.384898 -0.173033 -0.653783  0.722890       1   \n",
      "1  0.690775 -0.809868 -0.695485  0.752990       1   \n",
      "2  0.774262 -0.879583 -0.601859  0.773692       1   \n",
      "3  0.772516 -0.862276 -0.756446  0.812085       1   \n",
      "4  0.400888 -0.405238 -0.665966  0.872382       1   \n",
      "\n",
      "                                                text  \n",
      "0  Our Deeds are the Reason of this #earthquake M...  \n",
      "1             Forest fire near La Ronge Sask. Canada  \n",
      "2  All residents asked to 'shelter in place' are ...  \n",
      "3  13,000 people receive #wildfires evacuation or...  \n",
      "4  Just got sent this photo from Ruby #Alaska as ...  \n",
      "\n",
      "[5 rows x 770 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/processed_bert.csv')\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "data = df[[str(i) for i in range(768)]+[\"target\"]].values\n",
    "\n",
    "np.random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "text_embeddings = data[:,:-1]\n",
    "targets = data[:,-1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(text_embeddings, targets, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.832183908045977\n",
      "Test accuracy: 0.7977675640183848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codygrogan/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(random_state=0, max_iter=1000).fit(X_train, y_train)\n",
    "\n",
    "train_acc = clf.score(X_train, y_train)\n",
    "test_acc = clf.score(X_test, y_test)\n",
    "\n",
    "print(f'Train accuracy: {train_acc}')\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.997208538587849\n",
      "Test accuracy: 0.7741300065659882\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=300, max_depth=200, n_jobs=10).fit(X_train, y_train)\n",
    "\n",
    "train_acc = rf_clf.score(X_train, y_train)\n",
    "test_acc = rf_clf.score(X_test, y_test)\n",
    "\n",
    "print(f'Train accuracy: {train_acc}')\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.8044334975369458\n",
      "Test accuracy: 0.7951411687458962\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_clf = SVC(C=6).fit(X_train, y_train)\n",
    "\n",
    "train_acc = svm_clf.score(X_train, y_train)\n",
    "test_acc = svm_clf.score(X_test, y_test)\n",
    "\n",
    "print(f'Train accuracy: {train_acc}')\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss    cp     dur\n",
      "-------  ------------  -----------  ------------  ----  ------\n",
      "      1        \u001b[36m0.6461\u001b[0m       \u001b[32m0.6773\u001b[0m        \u001b[35m0.6068\u001b[0m     +  0.5581\n",
      "      2        \u001b[36m0.5940\u001b[0m       \u001b[32m0.7069\u001b[0m        \u001b[35m0.5813\u001b[0m     +  0.5616\n",
      "      3        \u001b[36m0.5774\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.5705\u001b[0m     +  0.5523\n",
      "      4        \u001b[36m0.5685\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m0.5599\u001b[0m     +  0.4420\n",
      "      5        \u001b[36m0.5588\u001b[0m       \u001b[32m0.7537\u001b[0m        \u001b[35m0.5473\u001b[0m     +  0.4631\n",
      "      6        \u001b[36m0.5514\u001b[0m       0.7504        \u001b[35m0.5448\u001b[0m        0.4907\n",
      "      7        \u001b[36m0.5454\u001b[0m       \u001b[32m0.7594\u001b[0m        \u001b[35m0.5376\u001b[0m     +  0.3648\n",
      "      8        \u001b[36m0.5399\u001b[0m       \u001b[32m0.7783\u001b[0m        \u001b[35m0.5284\u001b[0m     +  0.3639\n",
      "      9        \u001b[36m0.5361\u001b[0m       \u001b[32m0.7808\u001b[0m        \u001b[35m0.5224\u001b[0m     +  0.3637\n",
      "     10        \u001b[36m0.5339\u001b[0m       \u001b[32m0.7841\u001b[0m        \u001b[35m0.5193\u001b[0m     +  0.3636\n",
      "     11        \u001b[36m0.5320\u001b[0m       \u001b[32m0.7865\u001b[0m        \u001b[35m0.5163\u001b[0m     +  0.3643\n",
      "     12        \u001b[36m0.5297\u001b[0m       \u001b[32m0.7923\u001b[0m        \u001b[35m0.5132\u001b[0m     +  0.3646\n",
      "     13        \u001b[36m0.5280\u001b[0m       0.7923        \u001b[35m0.5111\u001b[0m        0.3648\n",
      "     14        \u001b[36m0.5265\u001b[0m       \u001b[32m0.7972\u001b[0m        \u001b[35m0.5097\u001b[0m     +  0.3645\n",
      "     15        \u001b[36m0.5252\u001b[0m       0.7947        \u001b[35m0.5087\u001b[0m        0.3660\n",
      "     16        \u001b[36m0.5242\u001b[0m       0.7964        \u001b[35m0.5083\u001b[0m        0.4120\n",
      "     17        \u001b[36m0.5233\u001b[0m       0.7964        \u001b[35m0.5081\u001b[0m        0.4365\n",
      "     18        \u001b[36m0.5220\u001b[0m       \u001b[32m0.7989\u001b[0m        \u001b[35m0.5070\u001b[0m     +  0.5649\n",
      "     19        \u001b[36m0.5203\u001b[0m       \u001b[32m0.8054\u001b[0m        \u001b[35m0.5042\u001b[0m     +  0.4881\n",
      "     20        \u001b[36m0.5185\u001b[0m       0.8054        \u001b[35m0.5024\u001b[0m        0.5515\n",
      "     21        \u001b[36m0.5164\u001b[0m       0.8030        \u001b[35m0.5014\u001b[0m        0.5387\n",
      "     22        \u001b[36m0.5159\u001b[0m       0.8021        \u001b[35m0.5009\u001b[0m        0.5458\n",
      "     23        0.5161       0.8013        \u001b[35m0.5007\u001b[0m        0.4065\n",
      "     24        0.5159       0.8021        \u001b[35m0.5006\u001b[0m        0.4277\n",
      "     25        \u001b[36m0.5157\u001b[0m       0.8038        0.5007        0.5049\n",
      "     26        \u001b[36m0.5148\u001b[0m       0.8046        0.5009        0.5429\n",
      "     27        \u001b[36m0.5144\u001b[0m       0.8038        0.5012        0.6239\n",
      "     28        0.5163       0.8038        0.5016        0.3764\n",
      "     29        0.5160       0.8038        0.5029        0.3636\n",
      "     30        0.5145       0.8030        0.5021        0.4208\n",
      "     31        \u001b[36m0.5122\u001b[0m       0.8038        0.5027        0.3764\n",
      "     32        \u001b[36m0.5121\u001b[0m       0.8021        0.5026        0.3651\n",
      "     33        \u001b[36m0.5119\u001b[0m       0.8021        0.5030        0.3652\n",
      "     34        \u001b[36m0.5114\u001b[0m       0.8030        0.5035        0.3656\n",
      "     35        \u001b[36m0.5108\u001b[0m       0.8030        0.5037        0.3636\n",
      "     36        \u001b[36m0.5106\u001b[0m       \u001b[32m0.8062\u001b[0m        \u001b[35m0.4976\u001b[0m     +  0.3637\n",
      "     37        \u001b[36m0.5103\u001b[0m       0.8030        0.5024        0.3646\n",
      "     38        0.5108       0.8021        0.5015        0.3640\n",
      "Stopping since valid_acc has not improved in the last 20 epochs.\n",
      "Train accuracy: 0.8068965517241379\n",
      "Test accuracy: 0.7826657912015759\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "from torch.nn import BCELoss\n",
    "import skorch\n",
    "\n",
    "from skorch.callbacks import EarlyStopping, Checkpoint\n",
    "\n",
    "num_epochs = 100\n",
    "checkpoint_dir = 'checkpoints/'\n",
    "\n",
    "callbacks = [EarlyStopping(patience=20, threshold=0.001, threshold_mode='abs', monitor='valid_acc', lower_is_better=False),\n",
    "            Checkpoint(monitor='valid_acc_best', f_params='DisasterClassifier.pt', dirname=checkpoint_dir)\n",
    "]\n",
    "\n",
    "net = skorch.NeuralNetBinaryClassifier(\n",
    "    NeuralNetwork,\n",
    "    module__input_size=768,\n",
    "    module__hidden_size=100,\n",
    "    module__output_size=1,\n",
    "    module__num_layers=6,\n",
    "    optimizer=Adam, \n",
    "    optimizer__weight_decay=0.00001,\n",
    "    lr=0.0001,\n",
    "    max_epochs=num_epochs, \n",
    "    batch_size=32, \n",
    "    device='cuda:0',\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "net.fit(X_train.astype(np.float32), y_train.astype(np.float32))\n",
    "net.load_params(f_params=checkpoint_dir+'DisasterClassifier.pt', f_optimizer=checkpoint_dir+'optimizer.pt', f_history=checkpoint_dir+'history.json')\n",
    "\n",
    "train_acc = net.score(X_train.astype(np.float32), y_train.astype(np.float32))\n",
    "test_acc = net.score(X_test.astype(np.float32), y_test.astype(np.float32))\n",
    "\n",
    "print(f'Train accuracy: {train_acc}')\n",
    "print(f'Test accuracy: {test_acc}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
